Just to learn about nanoGPT.

code reference: https://github.com/karpathy/ng-video-lecture

> 10.788929 M parameters
> step 0: train loss 4.2789, val loss 4.2800
> step 500: train loss 1.7174, val loss 1.8740
> step 1000: train loss 1.3936, val loss 1.6164
> step 1500: train loss 1.2646, val loss 1.5313
> step 2000: train loss 1.1881, val loss 1.5051
> step 2500: train loss 1.1232, val loss 1.4920
> step 3000: train loss 1.0679, val loss 1.4890
> step 3500: train loss 1.0130, val loss 1.4932
> step 4000: train loss 0.9625, val loss 1.5157
> step 4500: train loss 0.9095, val loss 1.5336
> step 4999: train loss 0.8557, val loss 1.5539
